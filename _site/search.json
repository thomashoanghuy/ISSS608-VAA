[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "Welcome to Capybara’s homepage.\nThis is my website to practice Data Visualization and web-building skills"
  },
  {
    "objectID": "TakehomeEx/TakehomeEx01.html",
    "href": "TakehomeEx/TakehomeEx01.html",
    "title": "Takehome Exercise 1",
    "section": "",
    "text": "Singapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2022 should be used to prepare the analytical visualisation. It is available at Department of Statistics, Singapore(in short SingStat).\nLet’s examine the data.\nWe have 1 excel dataset under xlsx format. Inside we found 3 worksheets: 2022(Total) / 2022 (Male) / 2022 (Female).\nEach worksheet has 5 columns as followed:\n\n\n\n\n\n\nPlanning Areas represents the names for each planning areas in Singapore.\nSubzone further divides Planning area into small zones.\nAge group represents the age groups for population between 0 and 90, with interval of 5 years (0-4 / 5-9 / 10-14 etc…)\nType of Dwelling represents the types of housing in this census.\nTotal is the number of populations for each categories.\n\n3 worksheets, represents numbers for Male populations, Female Population and Total.\nOur tasks would be creating visualizations from these raw data. Our choices of visualization will be using Age-Sex pyramid."
  },
  {
    "objectID": "TakehomeEx/TakehomeEx01.html#data-preparation",
    "href": "TakehomeEx/TakehomeEx01.html#data-preparation",
    "title": "Takehome Exercise 1",
    "section": "Data Preparation",
    "text": "Data Preparation\nFirst, Age-sex pyramid requires data to be split into male and females. The exercise also requires to split into 9 different planning areas.\nFirst we will copy the columns which contains the total number of male ( from 2022 (Male) worksheet ) and total number of female ( from 2022 (Female)) worksheet to 2022 (Total) worksheet, adding on as 6th and 7th columns.\n\n\n\n\n\nFrom here, we can create Pivot table which includes all the data under this worksheet.\n\n\n\n\n\nSelect entire worksheet 2022 (Total) as Data source\n\n\n\n\n\nThere will be a new worksheet created, as Pivot table.\nNow we will drag Planning Area to Rows box for the Pivot table. And we will choose Total as Values box \nNow we shall right click on the Sum of Total column and Sort from Largest to smallest. We will now select 9 most populous planning areas of Singapore. We shall filter and keep these 9 areas only.\n\nNext step, we drag in Males and Females (drag and drop to Pivot table Values box) and remove the Sums of Total from this Values box.\nWe will also add in the Age Group, under Rows box.\n\nWe will have a table of 9 most populous areas in Singapore, and their age-group smaller breakdown.\n\nWe will filter out the Total from these age group breakdown. (Because the total for each areas are already in bolden first row, so we don’t need this last row of Total anymore.\nWe shall copy this table and paste-special (values only) to a new worksheet.\n\nInsert a new column in between Rows Label and Sums of Male.\nCopy the age group over, we will separate: First column is only for name of Planning Areas ( Bedok, Choa Chu Kang, Hougang etc…) and second column will be only for Age Group."
  },
  {
    "objectID": "TakehomeEx/TakehomeEx01.html#our-final-worksheet-we-will-have-a-similar-worksheet-like-this-under-worksheet-sheet1",
    "href": "TakehomeEx/TakehomeEx01.html#our-final-worksheet-we-will-have-a-similar-worksheet-like-this-under-worksheet-sheet1",
    "title": "Takehome Exercise 1",
    "section": "Our final worksheet, we will have a similar worksheet like this ( under worksheet Sheet1)",
    "text": "Our final worksheet, we will have a similar worksheet like this ( under worksheet Sheet1)"
  },
  {
    "objectID": "TakehomeEx/TakehomeEx01.html#dashboard-building",
    "href": "TakehomeEx/TakehomeEx01.html#dashboard-building",
    "title": "Takehome Exercise 1",
    "section": "DASHBOARD BUILDING",
    "text": "DASHBOARD BUILDING\nOpen new Tableau window. Save and name it as your project.\nWe can drag the xlsx excel data into this Tableau window.\nDrag Sheet1 into the middle (this is the final data table above after data transformation from previous steps). We shall take this as our datasource.\nClick on Sheet 1 and we will create the first Tableau Sheet\n\nWe shall put drag these items to Columns: Sums of MALE , Sums of FEMALE and Rows: Planning Area\n\nNext, right click on one of the Axis and EDIT AXIS\n\nWe will tick the Reverse options, as well as rename the axis to “Male Population”\n\nWe shall repeat the same for Female side. (but do not tick the Reverse option).\nWe shall then right click Null value to exclude them from the filter\n\nFinally, we will have a pyramid graph, similar to this\n\n\n\n\n\nWe shall right on the Sheet 1, and duplicate this worksheet 9 times, one for each other areas.\nWe shall rename each worksheets as per each of the planning areas ( Bedok, Choa Chu Kang, Hougang etc…)\nThis is already a pyramid graph of Singapore populations for 9 most populous areas, but we still need to break down in term of age group.\n\nWe select Bedok sheet\nRight click on Filters of Planning Areas > Edit filters\n\nFor example, if this is worksheet for Bedok, we can exclude other areas.\n\nNext, we drag Age Group into Rows.\n\nRight click on Age Group > Filter > Exclude Total\nWe will have a pyramid graph for Bedok population only: Depict populations between Male and Female, with subsets of each age groups for Bedok areas only.\n\nNext is aesthetics, where we have to input colours to make things more distinctive.\nThe recommendation would be one half (Male) would be warm and light color, while the other half should carry darker and cold color.\n\nWe repeat the same steps above for all 9 planning areas. Remember to maintain the same color codes / formats for all 9 areas."
  },
  {
    "objectID": "TakehomeEx/TakehomeEx01.html#lastly-we-can-building-dashboard.",
    "href": "TakehomeEx/TakehomeEx01.html#lastly-we-can-building-dashboard.",
    "title": "Takehome Exercise 1",
    "section": "Lastly, we can building Dashboard.",
    "text": "Lastly, we can building Dashboard.\nCreate new dashboard\n\nWe choose Floating as the setting and choose Vertical objects\n\nWe divide dashboard into 9 evenly horizontal rectangle containers. Next we drag each of the Sheets into each of these container.\n\n\nRemember to change Standard to Entire view to see entire graph.\nAlso click on Device Preview and view as Large Desktop Monitor (2560 x 1440) And click on Size ( default is Fixed) and change to Automatic.\nAfter dragging each planning areas into the container. Remove the labels and ledgers ( Plannings Areas, Sum of Male and Sums of Females.\nPlay around with the 9 planning areas (alignments of lines and borders, colours etc..)"
  },
  {
    "objectID": "TakehomeEx/TakehomeEx01.html#final-results-would-look-similar-to-this.",
    "href": "TakehomeEx/TakehomeEx01.html#final-results-would-look-similar-to-this.",
    "title": "Takehome Exercise 1",
    "section": "Final results would look similar to this.",
    "text": "Final results would look similar to this."
  },
  {
    "objectID": "TakehomeEx/TakehomeEx01.html#publishing-dashboard",
    "href": "TakehomeEx/TakehomeEx01.html#publishing-dashboard",
    "title": "Takehome Exercise 1",
    "section": "Publishing Dashboard",
    "text": "Publishing Dashboard\nFinally, we can go to Data / Sheet1 / Extract Data\nAfter data extraction (saving Tableau working as .hyper file), we can go to Server > Tableau Public > Save to Tableau Public.\nIf you have logged in to your Tableau public account, this will be uploaded as a new Viz under your profile.\nYou can view my published Viz under this link\nSingapore Population Distribution"
  },
  {
    "objectID": "TakehomeEx/TakehomeEx01.html#summary",
    "href": "TakehomeEx/TakehomeEx01.html#summary",
    "title": "Takehome Exercise 1",
    "section": "SUMMARY",
    "text": "SUMMARY"
  },
  {
    "objectID": "TakehomeEx/TakehomeEx01.html#commentaries-on-the-data",
    "href": "TakehomeEx/TakehomeEx01.html#commentaries-on-the-data",
    "title": "Takehome Exercise 1",
    "section": "Commentaries on the Data",
    "text": "Commentaries on the Data\nThere is a general assumption about Singapore population: Singapore is having an aging population. The general trend observable from the pyramid graphs of 9 different planning areas in Singapore show that they are all middle heavy (meaning the highest segment of population are among the working adults between 25- to 60 years old).\nWhile it is natural that the bottom of these pyramid graph, which represent the elderly populations, are small, due to death, it is indeed an evident of an aging population when most of the top portions of the pyramids are also small. This shows that Singaporean at family-planning age (at the age 25-60 years old) , are not having children, hence the low fertility rate and a smaller tops of the pyramids\nA closer look at different planning areas, can give us some patterns on different geographical distributions as well. Generally, other 7 out of 9 areas in this dashboard, for the age between 0 and 20, the younger, the smaller are the population numbers, while the adolescent population are largest among pre-adults’ population. Except Punggol and Sengkang, these 2 areas see the highest percentage of populations of children age, when compared to the rest of population of the area. This may suggest that Sengkang and Punggol are two areas where there are many young families / couples are having children.\nThe gender distribution of Singapore’s population is relatively balanced, However, there are slight variations in the gender distribution among different age groups. For example, among children aged 0-14, there are slightly more males than females. However, among adults aged 15-64, there are slightly more females than males. And among older adults aged 75 and above, there are more females than males. This is because female tend to have higher life expectancy than male.\nFurther breakdown by planning areas, Punggol and Sengkang are 2 areas with highest portion of populations among the 25-40 years old, millennial prime working populations, compared to the other age groups in the same areas. This means the average ages of population among these 2 areas would be lower, compared to other matured estates.\nIn conclusion, while some of areas of Singapore are consisting of younger populations and children / teenage populations, overall, Singapore is still foreseen to encounter an aging population. With majority of graphs are middle heavy ( the working adults age between 25-60), these segment of population will eventually grow older and move to older age groups, while the smaller top populations of children and teenagers are too small to replace the current working adult population. If this is not addressed urgently by the government, this will lead to many social and economic and healthcare problems for the country within next few decades."
  },
  {
    "objectID": "TakehomeEx/TakehomeEx01.html#about-this-site.",
    "href": "TakehomeEx/TakehomeEx01.html#about-this-site.",
    "title": "Takehome Exercise 1",
    "section": "About this site.",
    "text": "About this site.\nThis is capybara first site that help me start learning Data visualization with many tools\n\nData Preparation and Cleaning with Excel\nData Visualization by Tableau\nWebsite Design by HTML and R Studio tools to create , render , commit onto Github and subsequently publishing on Netlify"
  },
  {
    "objectID": "TakehomeEx/TakehomeEx02.html",
    "href": "TakehomeEx/TakehomeEx02.html",
    "title": "TakeHome Exercise 2",
    "section": "",
    "text": "In the first task, we are supposed to create Age-sex Pyramid to cover 9 planning areas of Singapore in term of Male/ Female and the age group.\nBelow is one of the DataViz that was created by a classmate.\nhttps://public.tableau.com/app/profile/ruipeng.wang/viz/take_home_01/Dashboard1?fbclid=IwAR1xjLcdtI9B6IQsXvE8DeuHGT0Xe1sL20M6RPAZ2gvhEV_hLizpZ9QdADg\n\nOriginal DataViz\nCritiques:\n\nClarity: The viz was created for 9 planning areas with 9 different populations. However, they use to same absolute scales in terms of number of people. Therefore, the areas with small number of populations ( Downtown Core and Outram) when putting in the same x-axis scale as other areas, does not have high enough number of people, to show case the distributions as Age-sex pyramid.\nClarity Some age groups have data labels ( number of people in that age group), however many age groups do not have any data labels. It looks like the data label are randomly assigned.\nAesthetics Age-sex pyramid of 9 area, should not occupy such big area of spaces (taking up entire horizontal dataviz). There are other designs that can save spaces for other graphs / charts that will portray more information from the data."
  },
  {
    "objectID": "TakehomeEx/TakehomeEx02.html#age-sex-pyramid-graph-for-bedok",
    "href": "TakehomeEx/TakehomeEx02.html#age-sex-pyramid-graph-for-bedok",
    "title": "TakeHome Exercise 2",
    "section": "AGE-SEX PYRAMID GRAPH FOR BEDOK",
    "text": "AGE-SEX PYRAMID GRAPH FOR BEDOK\nWe use fill = bedok_df$ID (the new column added) is to separate the 2 genders.\n\nggplot(bedok_df,\n       aes( x = bedok_df$`Population Perc` , y = bedok_df$`AGE GROUP` , fill = bedok_df$ID ))+\n  geom_bar(stat = \"identity\") +\n  ggtitle(\"Distribution of Bedok\")+\n  ylab(\"AGE GROUP\")+\n  xlab(\"Percentage of Area Population\") +\n  labs(fill = \"Gender\")+\n  scale_x_continuous(breaks = scales::pretty_breaks(n = 10))\n\nWarning: Use of `` bedok_df$`Population Perc` `` is discouraged.\nℹ Use `Population Perc` instead.\n\n\nWarning: Use of `` bedok_df$`AGE GROUP` `` is discouraged.\nℹ Use `AGE GROUP` instead.\n\n\nWarning: Use of `bedok_df$ID` is discouraged.\nℹ Use `ID` instead.\n\n\n\n\n\nFinally we have created a Age-Sex pyramid, using percentage of the Population of the area, rather than their absolute numbers.\nAs such, even with the area of low population (like Outram or Downtown Core) , each age groups will still be better visualized using percentage of its own population.\nWe can repeat this same steps for any planning areas in our original data."
  },
  {
    "objectID": "TakehomeEx/TakehomeEx02.html#pyramid-graph-for-9-planning-areas-population-by-gender",
    "href": "TakehomeEx/TakehomeEx02.html#pyramid-graph-for-9-planning-areas-population-by-gender",
    "title": "TakeHome Exercise 2",
    "section": "PYRAMID GRAPH FOR 9 PLANNING AREAS POPULATION, BY GENDER",
    "text": "PYRAMID GRAPH FOR 9 PLANNING AREAS POPULATION, BY GENDER\nWith the combined dataframe, we can draw the pyramid graph using the ggplot2 now\n\nggplot(sg_pop,\n       aes( x = Population , y = Area , fill = Gender))+\n  geom_bar(stat = \"identity\") +\n  ggtitle(\"SINGAPORE POPULATION DISTRIBUTION\")+\n  ylab(\"AREA\")+\n  xlab(\"Population\") +\n  labs(fill = \"Gender\")\n\n\n\n  scale_x_continuous(labels = scales::comma_format(big.mark = ',' , decimal.mark = '.') , breaks = scales::pretty_breaks(n = 5))\n\n<ScaleContinuousPosition>\n Range:  \n Limits:    0 --    1\n\n\nAs you can see, Outram and Downtown Core have the lowest number of population among the 9 chosen area. While Woodlands have the largest population."
  },
  {
    "objectID": "TakehomeEx/TakehomeEx03.html",
    "href": "TakehomeEx/TakehomeEx03.html",
    "title": "Take Home Exercise 03",
    "section": "",
    "text": "In this take-home exercise, we will study the patterns of the resale prices of public housing property by residential towns and estates in Singapore by using appropriate analytical visualisation techniques learned in Lesson 4: Fundamentals of Visual Analytics.\nFor the purpose of this study, the focus should be on 3-ROOM, 4-ROOM and 5-ROOM types."
  },
  {
    "objectID": "TakehomeEx/TakehomeEx03.html#room-average-resale-prices",
    "href": "TakehomeEx/TakehomeEx03.html#room-average-resale-prices",
    "title": "Take Home Exercise 03",
    "section": "4-ROOM average resale prices",
    "text": "4-ROOM average resale prices\n\nfour_roomdf1 = four_roomdf[c(\"month\"  , \"price_per_sqm\" )]\nfourrooms_monthly_avg2 = four_roomdf1 %>%\ngroup_by(month) %>%\nsummarise(average_price_sqm2 = mean(price_per_sqm))\n\n\np1 = ggplot(fourrooms_monthly_avg2, aes(x= fourrooms_monthly_avg2$month, y=fourrooms_monthly_avg2$average_price_sqm2 , group = 1)) +\n  geom_smooth() + geom_point()+\n  theme(axis.text.x=element_text(angle=90, hjust=1))+\n  xlab(\"Month\")+ylab(\"Average Price 4 room flat\")\n\np1"
  },
  {
    "objectID": "TakehomeEx/TakehomeEx03.html#room-average-resale-prices-1",
    "href": "TakehomeEx/TakehomeEx03.html#room-average-resale-prices-1",
    "title": "Take Home Exercise 03",
    "section": "5-ROOM average resale prices",
    "text": "5-ROOM average resale prices\n\nfive_roomdf1 = five_roomdf[c(\"month\"  , \"price_per_sqm\" )]\nfiveroom_monthly_avg3 = five_roomdf1 %>%\ngroup_by(month) %>%\nsummarise(average_price_sqm2 = mean(price_per_sqm))\n\n\nfiveroom_monthly_avg4 <- fiveroom_monthly_avg3 %>%\n  separate(month,\n           into = c(\"year_no\", \"month_no\"),\n           sep = \"-\",\n           convert = TRUE)\n\n\np2 = ggplot(fiveroom_monthly_avg4, aes(x= fiveroom_monthly_avg3$month, y=fiveroom_monthly_avg3$average_price_sqm2 , group = 1)) +\n  geom_smooth() + geom_point()+\n  theme(axis.text.x=element_text(angle=90, hjust=1))+\n  xlab(\"Month\")+ylab(\"Average Price 5 room flat\")\n\nanimate (p2 + transition_time(fiveroom_monthly_avg4$month_no) + labs(title = \"Month from 2017 - 2023: {frame_time}\")) \n\n\n\n\nAs you can see, 4 rooms and 5 room types of flats have similar trends, from 2017, it was on the downtrend up til 2019 before started picking up and increased until current year 2023.\nThe difference are, for 4 room and 5 rooms units, there are some months where there are big outliers, and the standard deviation away from the trend-line are much bigger compared to 3-Room type of flats. This means for 4 rooms and 5 room types of flats, there are certain transactions that are priced at much different prices compared to the group’s trend line"
  },
  {
    "objectID": "TakehomeEx/TakehomeEx03.html#averge-price-per-sqm-versus-lease-remains-number-of-years",
    "href": "TakehomeEx/TakehomeEx03.html#averge-price-per-sqm-versus-lease-remains-number-of-years",
    "title": "Take Home Exercise 03",
    "section": "AVERGE PRICE PER SQM versus LEASE REMAINS NUMBER OF YEARS",
    "text": "AVERGE PRICE PER SQM versus LEASE REMAINS NUMBER OF YEARS\n\np3 <-ggplot(df_345,\n       aes(x = lease_remains,\n           y = price_per_sqm ,\n           colour = flat_type)) +\n  geom_point() +\n  labs(title = \"Resale price per square meter verus Remaining lease years\",\n       x = \"Remaining Lease (Years)\",\n       y = \"Resale price ($psm)\",\n       fill =\"Flat type\",\n       caption = \"Month From 2017 - 2023: {frame_time}\")+\n  geom_smooth(method=\"lm\",\n              se = FALSE,\n              color = \"yellow\",\n              formula = y ~ x)+\n  facet_grid(flat_type ~ .)+\n  theme(legend.position = \"none\")+\n  transition_time(df_345$month_no) + ease_aes('linear')\n  \nanimate(p3, nframes = 10 , fps = 0.5)\n\n\n\n\nThe above charts show us that the average prices of HDB units in Singapore against the remaining lease years of the units for at least 3 groups, the 3-ROOM, 4 ROOM and 5 ROOM. While the yellow line shows that there are certain truth when the longer the remaining lease are, the higher the average prices of the units.\nHowever the steepness of the yellow line shows that the correlation is not really extreme, across 40 years between 50 years remaining units and 95 years units, the average price per square meter does not increase that much. In other words, this shows that even average values of HDB does not depreciate due to the lease running down."
  },
  {
    "objectID": "InClassExercise/inclass05/inclass05.html",
    "href": "InClassExercise/inclass05/inclass05.html",
    "title": "In-Class Exercise 05",
    "section": "",
    "text": "pacman::p_load(corrplot, tidyverse, ggstatsplot)\n\n#IMPORTING AND PREPARING THE DATASET#\n\nwine = read_csv(\"data/wine_quality.csv\")\n\nRows: 6497 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): type\ndbl (12): fixed acidity, volatile acidity, citric acid, residual sugar, chlo...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\npairs(wine[,1:11])\n\n\n\n\n\n#| fig-dpi: 75\n#these will affect the placement of the graph on the quarto page (maximum is 14)\n#fig dpi is default 30, if increase sharpness by increase to 75 or 100\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11, \n    ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are no significant at p < 0.05\"\n) \n\n\n\n\n\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)\n\n\n\n\n\nwine.cor = cor(wine[,1:11])\n\n\ncorrplot(wine.cor)\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\",\n         diag = FALSE,\n         tl.col = \"black\")\n\n\n\n\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n##Combining corrgram with the significant test##\nWith corrplot package, we can use the cor.mtest() to compute the p-values and confidence interval for each pair of variables.\n\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\n\nWe can then use the p.mat argument of corrplot function as shown in the code chunk below.\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)\n\n\n\n\n###Reorder a corrgram By default, the order of attributes of a corrgram is sorted according to the correlation matrix (i.e. “original”). The default setting can be over-write by using the order argument of corrplot(). Currently, corrplot package support four sorting methods, they are:\n“AOE” is for the angular order of the eigenvectors. “FPC” for the first principal component order. “hclust” for hierarchical clustering order, and “hclust.method” for the agglomeration method to be used. “hclust.method” should be one of “ward”, “single”, “complete”, “average”, “mcquitty”, “median” or “centroid”. “alphabet” for alphabetical order.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\npop_data <- read_csv(\"data/respopagsex2000to2018_tidy.csv\")  \n\nRows: 108126 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): PA, SZ, AG\ndbl (2): Year, Population\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\ntail(pop_data)\n\n# A tibble: 6 × 5\n  PA     SZ          AG         Year Population\n  <chr>  <chr>       <chr>     <dbl>      <dbl>\n1 Yishun Yishun West AGE85over  2013        400\n2 Yishun Yishun West AGE85over  2014        450\n3 Yishun Yishun West AGE85over  2015        510\n4 Yishun Yishun West AGE85over  2016        560\n5 Yishun Yishun West AGE85over  2017        590\n6 Yishun Yishun West AGE85over  2018        620\n\n\n\nagpop_mutated <- pop_data %>%\n  mutate(`Year` = as.character(Year))%>%\n  spread(AG, Population)%>%\n  mutate(YOUNG = rowSums(.[4:8]))%>%\n  mutate(ACTIVE = rowSums(.[9:16]))  %>%\n  mutate(OLD = rowSums(.[17:21])) %>%\n  mutate(TOTAL = rowSums(.[22:24])) %>%\n  filter(Year == 2018)%>%\n  filter(TOTAL > 0)\n\n\nagpop_mutated\n\n# A tibble: 234 × 25\n   PA        SZ    Year  AGE0-…¹ AGE05…² AGE10…³ AGE15…⁴ AGE20…⁵ AGE25…⁶ AGE30…⁷\n   <chr>     <chr> <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 Ang Mo K… Ang … 2018      180     270     320     300     260     300     270\n 2 Ang Mo K… Chen… 2018     1060    1080    1080    1260    1400    1880    1940\n 3 Ang Mo K… Chon… 2018      900     900    1030    1220    1380    1760    1830\n 4 Ang Mo K… Kebu… 2018      720     850    1010    1120    1230    1460    1330\n 5 Ang Mo K… Semb… 2018      220     310     380     500     550     500     300\n 6 Ang Mo K… Shan… 2018      550     630     670     780     950    1080     990\n 7 Ang Mo K… Tago… 2018      260     340     430     500     640     690     440\n 8 Ang Mo K… Town… 2018      830     930     930     860    1020    1400    1350\n 9 Ang Mo K… Yio … 2018      160     160     220     260     350     340     230\n10 Ang Mo K… Yio … 2018      810    1070    1300    1450    1500    1590    1390\n# … with 224 more rows, 15 more variables: `AGE35-39` <dbl>, `AGE40-44` <dbl>,\n#   `AGE45-49` <dbl>, `AGE50-54` <dbl>, `AGE55-59` <dbl>, `AGE60-64` <dbl>,\n#   `AGE65-69` <dbl>, `AGE70-74` <dbl>, `AGE75-79` <dbl>, `AGE80-84` <dbl>,\n#   AGE85over <dbl>, YOUNG <dbl>, ACTIVE <dbl>, OLD <dbl>, TOTAL <dbl>, and\n#   abbreviated variable names ¹​`AGE0-4`, ²​`AGE05-9`, ³​`AGE10-14`, ⁴​`AGE15-19`,\n#   ⁵​`AGE20-24`, ⁶​`AGE25-29`, ⁷​`AGE30-34`\n\n\n\nagpop_mutated %>%\nselect(\"PA\" , \"SZ\" , \"YOUNG\" , \"ACTIVE\" , \"OLD\" , \"TOTAL\")\n\n# A tibble: 234 × 6\n   PA         SZ                     YOUNG ACTIVE   OLD TOTAL\n   <chr>      <chr>                  <dbl>  <dbl> <dbl> <dbl>\n 1 Ang Mo Kio Ang Mo Kio Town Centre  1330   2770   730  4830\n 2 Ang Mo Kio Cheng San               5880  16970  5480 28330\n 3 Ang Mo Kio Chong Boon              5430  15700  5960 27090\n 4 Ang Mo Kio Kebun Bahru             4930  13300  4780 23010\n 5 Ang Mo Kio Sembawang Hills         1960   3620  1200  6780\n 6 Ang Mo Kio Shangri-La              3580   9600  3360 16540\n 7 Ang Mo Kio Tagore                  2170   4650  1300  8120\n 8 Ang Mo Kio Townsville              4570  12580  4800 21950\n 9 Ang Mo Kio Yio Chu Kang East       1150   2410   640  4200\n10 Ang Mo Kio Yio Chu Kang West       6130  14580  4270 24980\n# … with 224 more rows\n\n\n\npacman::p_load(ggtern, plotly, tidyverse)\n\n\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) + geom_point()+\n  labs(title = \"Population Structure, 2015\")+\n  theme_rgbg()\n\n\n\n\n##If you write it in basic plot_ly, the graph will be more interactive interface compared to using ggtern##\n\nlabel <- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\naxis <- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes <- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %>%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )\n\nNo scatterternary mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -> https://plotly.com/r/reference/#scatter-mode\n\n\n\n\n\n\n\npacman::p_load(seriation, dendextend, heatmaply, tidyverse)\n\n\nwh <- read_csv(\"data/WHData-2018.csv\")\n\nRows: 156 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): Country, Region\ndbl (10): Happiness score, Whisker-high, Whisker-low, Dystopia, GDP per capi...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nrow.names(wh) <- wh$Country\n\nWarning: Setting row names on a tibble is deprecated.\n\n\n##Purpose of the above step is to take the column Country TO MAKE THEM the names of the rows in the dataframe, instead of automatic 1,2,3,4 numeric name##\n\nwh\n\n# A tibble: 156 × 12\n   Country        Region Happi…¹ Whisk…² Whisk…³ Dysto…⁴ GDP p…⁵ Socia…⁶ Healt…⁷\n * <chr>          <chr>    <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 Albania        Centr…    4.59    4.70    4.48    1.46   0.916   0.817   0.79 \n 2 Bosnia and He… Centr…    5.13    5.22    5.04    1.88   0.915   1.08    0.758\n 3 Bulgaria       Centr…    4.93    5.02    4.84    1.22   1.05    1.52    0.712\n 4 Croatia        Centr…    5.32    5.40    5.24    1.77   1.12    1.16    0.737\n 5 Czech Republic Centr…    6.71    6.78    6.64    2.49   1.23    1.49    0.854\n 6 Estonia        Centr…    5.74    5.82    5.66    1.46   1.2     1.53    0.737\n 7 Hungary        Centr…    5.62    5.70    5.54    1.97   1.17    1.40    0.732\n 8 Kosovo         Centr…    5.66    5.76    5.57    2.26   0.855   1.23    0.578\n 9 Latvia         Centr…    5.93    6.00    5.86    2.14   1.15    1.45    0.671\n10 Lithuania      Centr…    5.95    6.04    5.87    2.13   1.20    1.53    0.716\n# … with 146 more rows, 3 more variables: `Freedom to make life choices` <dbl>,\n#   Generosity <dbl>, `Perceptions of corruption` <dbl>, and abbreviated\n#   variable names ¹​`Happiness score`, ²​`Whisker-high`, ³​`Whisker-low`,\n#   ⁴​Dystopia, ⁵​`GDP per capita`, ⁶​`Social support`, ⁷​`Healthy life expectancy`\n\n\n\nwh1 <- dplyr::select(wh, c(3, 7:12))\nwh_matrix <- data.matrix(wh)\n\n##wh_matrix is MATRIX, not a data table as per original wh dataframe anymore. We can only draw heatmap on matrix, rather than plain dataframe.##\n###We use heatmaply to draw this matrix into heatmap, notice that the graph is interactive!###\n\nwh_heatmap <- heatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\nwh_heatmap\n\n\n\n\n\n###Note: Normalising method### When variables in the data comes from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations. This preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\nOn other hands, ###Note: Percentising method### 1) This is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank. 2) This is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile. 3) The benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n#Clustering Algo# heatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:\n##1) Manual approach## In the code chunk below, the heatmap is plotted by using hierachical clustering algorithm with “Euclidean distance” and “ward.D” method.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n##2) Statistical approach## ###First, we have to find best clustering method should be used on this dataset### We use dend_expend for this\n\nwh_d <- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nAs you can see, average method is the most optimum with the highest score 0.67\n###Second, we need to find what is the optimal number of cluster### We should use find_k() for this step\n\nwh_clust <- hclust(wh_d, method = \"average\")\nnum_k <- find_k(wh_clust)\nplot(num_k)\n\n\n\n\nAs we can see, the optimal k = 3.\nWith that, we can use this statistical analysis result to do the code\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)\n\n\n\n\n\n#Finishing# In the code chunk below the following arguments are used:\nk_row is used to produce 5 groups. margins is used to change the top margin to 60 and row margin to 200. fontsizw_row and fontsize_col are used to change the font size for row and column labels to 4. main is used to write the main title of the plot. xlab and ylab are used to write the x-axis and y-axis labels respectively.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )\n\n\n\n\n\n##Plotting Static Parallel Coordinates Plot##\n\npacman::p_load(GGally, parallelPlot, tidyverse)\n\n\nggparcoord(data = wh, \n           columns = c(7:12))\n\n\n\n\n##Plotting Static Parallel Coordinates with BOX PLOT##\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")\n\nWarning: The following aesthetics were dropped during statistical transformation: colour\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\n##DRAWING PARALLEL COORDINATE WITH PARRALLEL PLOT USING parallelplot, will allow BRUSHING (INTERACTIVE)## Mean you can choose a column (for example Happiness Score) and we can highlight a portion of that column, and it will make highlight the rest of the data.\nWe can see what whether people with highest happiness score, such as 8 / 7.5 / 7, whether they have highest GDP, highest SOCIAL SUPPORT or HEALTHY LIFE EXPECTATION\n\nwh <- wh %>%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250)\n\n\n\n\n\n\nparallelPlot(wh,\n             rotateTitle = TRUE)\n\n\n\n\n\n\nhistoVisibility <- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)"
  },
  {
    "objectID": "HandsonExercise/handsonex01.html",
    "href": "HandsonExercise/handsonex01.html",
    "title": "HandsonEx01",
    "section": "",
    "text": "Install and Launching R packages The code chunk below use p_load of pacman package to check if tidyverse packages are installed in te environment, it will luanch it into R if it has been installed.\n\npacman::p_load(tidyverse, ggplot2, forcats)\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\", \n                      show_col_types = FALSE)\n\nView Math Result using R hist\n\nhist(exam_data$MATHS,\n     main = \"Histogram of Maths Exams Result\",\n     xlab = \"Score\",\n     xlim = c(0, 100),\n     ylab = \"Count\",\n     ylim = c(0, 80),\n     col = \"green\",\n     freq = TRUE)\n\n\n\n\nDo the same thing but in ggplot\n\nggplot(data = exam_data, aes(x = MATHS)) + \n  \n  geom_histogram(bins = 10, \n                 boundary = 100, \n                 color = \"black\",\n                 fill = \"lightblue\") +\n  \n  labs(title = \"Histogram of Math Exam Results\", \n       subtitle = \"Maths\",\n       x = \"Score\",\n       y = \"Count\") +\n  \n  theme_bw()\n\n\n\n\nOn ggplot2, you can use other types of graphs and not only restricted to 1 function\n\nggplot(data = exam_data,\n       aes(x = MATHS)) +\n  geom_dotplot(binwidth = 2.5, dotsize = 0.5) +\n  scale_y_continuous(NULL, breaks = NULL) +\n  theme_bw()\n\n\n\n\nView Math Result using ggplot2 histogram, notice the smaller number of bins\n\nggplot(data = exam_data,\n       aes(x = MATHS)) +\n  geom_histogram(bins = 20,\n                 color = \"black\",\n                 fill = \"lightblue\") +\n  theme_bw()\n\n\n\n\nNow to combine with other information, such as gender.\n\nggplot(data = exam_data,\n       aes(x = MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins = 20,\n                 color = \"lightblue\")+\n  theme_bw()\n\n\n\n\nComparing between 2 genders by ggplot density\n\nggplot(data = exam_data,\n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density() + \n  theme_bw()\n\n\n\n\nGgplot Boxplot (notched)\n\nggplot(data = exam_data,\n       aes(y = MATHS, \n           x = GENDER)) +\n  geom_boxplot(notch = TRUE) +\n  theme_bw()\n\n\n\n\nGGPLOT Boxplot and Point\n\nggplot(data = exam_data,\n       aes(y = MATHS, \n           x = GENDER)) +\n  geom_boxplot() +\n  geom_point(position = \"jitter\", size = 0.5) + \n  theme_bw()\n\n\n\n\nGGplot Boxplot with Violin plot\n\nggplot(data = exam_data,\n       aes(y = MATHS, \n           x = GENDER)) +\n  geom_violin(fill = \"lightblue\") +\n  geom_boxplot(alpha = 0.5) + \n  theme_bw()\n\n\n\n\nNow, you can combine boxplot with Stats summary (mean)\n\nggplot(data = exam_data,\n       aes(y = MATHS, \n           x = GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",\n               fun = \"mean\",\n               colour = \"red\",\n               size = 4) + \n  theme_bw()\n\n\n\n\nNOTE: Math score is a continuous variable , while Gender is nominal variable (categorized and cannot be organized into orders/sequences), we can use boxplot to draw the Bivariate relationship between these 2 types of variables\nHowever, but TWO continuous variables, we can use something else\nGGPLOT geom_point between English and Maths scores ( also known as Scatterplot )\n\nggplot(data = exam_data,\n       aes(x = MATHS, \n           y = ENGLISH)) +\n  geom_point() + \n  theme_bw()\n\n\n\n\nNow if we attempt to draw a fitted line through this scatterplot to see the trend\n\nggplot(data = exam_data,\n       aes(x = MATHS, \n           y = ENGLISH)) +\n  geom_point() +\n  # default method used for smooth is loess\n  # geom_smooth(linewidth = 0.5)\n  geom_smooth(linewidth = 0.5, method = lm) +\n  coord_cartesian(xlim = c(0, 100), ylim = c(0, 100)) + #this is to make sure both axis start from 0 and max = 100\n  theme_bw()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nView results by splitting them into each classes (try with historgram) by this function facet_wrap\n\nggplot(data = exam_data,\n       aes(x = MATHS)) +\n  geom_histogram(bins = 20) +\n    facet_wrap(~ CLASS) + \n  theme_bw()\n\n\n\n\ninstead, if we use facet_grid\n\nggplot(data = exam_data,\n       aes(x = MATHS)) +\n  geom_histogram(bins = 20) +\n    facet_grid(~ CLASS) + \n  theme_bw()\n\n\n\n\nFacet_grid can look better if one of the variables are of smaller number of categories, such as gender\n\nggplot(data = exam_data, aes(y = MATHS, x = CLASS)) +\n  geom_boxplot() + \n    facet_grid(cols = vars(GENDER)) + \n      theme_bw()\n\n\n\n\nOr we can split them horizontally by using facet_grid(rows*)\n\nggplot(data = exam_data, aes(y = MATHS, x = CLASS)) +\n  geom_boxplot() + \n    facet_grid(rows = vars(GENDER)) +\n      theme_bw()\n\n\n\n\nSame thing, we can play around with theme. First we plot b ggplot, use coord_flip() to flip the axis Then we assign the plot to a variable P, then we can design the theme() separately\n\np <- ggplot(data = exam_data, \n            aes(x = RACE)) +\n\n      geom_bar() + \n  \n      coord_flip()\n\np + theme(panel.background = \n            element_rect(fill = \"lightblue\", \n              colour = NULL)\n          )\n\n\n\n\n#ADDING IN DATA INTO THE VISUALIZATION OF GGPLOT#\nWe calculate the percentage of races of each students by using mutate() to add in new column for exam_data table. And we use fct_infreg() on RACE column to calculate the percentage of each race.\nGeom_text is to add in the percentages for each of the columns\n\npct_format = scales::percent_format(accuracy = .1)\n\nexam_data %>%\n  mutate(RACE = fct_infreq(RACE)) %>%\n\nggplot((aes(x = RACE))) +geom_bar() +\n  geom_text(aes(label = sprintf('%d (%s)', \n                            after_stat(count), \n                            pct_format(after_stat(count) / sum(after_stat(count)))\n                            )\n                ),\n            stat=\"count\",\n            nudge_y = 8 ) +\n  labs(title = \"No. of Pupils by Race in Exam Results\", \n       y=\"No. of Pupils\") \n\n\n\n\nIf you want to add in colors for each bar by adding in fill for geom_bar aes() = geom_bar(aes(fill = RACE ), show.legend = TRUE)\n\npct_format = scales::percent_format(accuracy = .1)\n\nexam_data %>%\n  mutate(RACE = fct_infreq(RACE)) %>%\n\nggplot((aes(x = RACE))) +geom_bar(aes(fill = RACE ), show.legend = TRUE ) +\n  geom_text(aes(label = sprintf('%d (%s)', \n                            after_stat(count), \n                            pct_format(after_stat(count) / sum(after_stat(count)))\n                            )\n                ),\n            stat=\"count\",\n            nudge_y = 8 ) +\n  labs(title = \"No. of Pupils by Race in Exam Results\", \n       y=\"No. of Pupils\") \n\n\n\n\n##Adding in Means and median lines on Histogram diagram above##\nWe can add in geom_vline and use xintercept = mean of the Math score AND xintercept = median\n\nggplot(data = exam_data, aes(x = MATHS)) +\n\n  geom_histogram(bins = 20, color = \"brown\", fill=\"grey\") +\n  \n  geom_vline(xintercept = mean(exam_data$MATHS), \n             linetype=\"dashed\", \n             linewidth=1, \n             colour=\"red\") + \n  \n  geom_vline(xintercept = median(exam_data$MATHS), \n             linetype=\"dashed\", \n             linewidth=1, \n             colour=\"black\") + \n  \n  theme_bw()\n\n\n\n\n###WHAT IF WE PLOT TWO geom_histogram at the same time, but we use fill= Gender and use facet_grid to seperate them by gender### The overall entire ENGLISH score lightgrey color is in the background, however, the 2nd histogram is filled with aes(fill= GENDER) and facet_grid seperate them into 2 diagrams Without this facet_grid, 2 geom_histogram will basically plot the same data and the lightgrey graph will not appear.\n\nggplot(data = exam_data, aes(x = ENGLISH)) +\n  geom_histogram(data = exam_data[\"ENGLISH\"], \n                 bins = 20, \n                 fill=\"lightgrey\", \n                 alpha=0.5) +\n  geom_histogram(aes(fill=GENDER), \n                 col=\"black\", \n                 bins = 20) +\n  facet_grid(cols = vars(GENDER)) +\n  theme_bw()\n\n\n\n\nWe can use geom_vline and geom_hline to create a fix scale on the graph. coor_cartesian will force both x and y axis to have the same min =0 and max = 100\n\nggplot(data = exam_data,\n       aes(x = MATHS, y = ENGLISH)) +\n  \n  geom_point() + \n  \n  geom_vline(xintercept = mean(50), \n             linetype=\"dashed\", \n             linewidth=1, \n             colour=\"grey\") +\n  \n  geom_hline(yintercept = mean(50), \n             linetype=\"dashed\", \n             linewidth=1, \n             colour=\"grey\") + \n  \n  coord_cartesian(xlim = c(0, 100), \n                  ylim = c(0, 100)) + \n  theme_bw()\n\n\n\n\nHowever, above geom_vline and geom_hline, we fixed the x_intercept = 50 and y_intercept = 50 What if we set them = mean of the data.\n\nggplot(data = exam_data,\n       aes(x = MATHS, y = ENGLISH)) +\n  \n  geom_point() + \n  \n  geom_vline(xintercept = mean(exam_data$MATHS), \n             linetype=\"dashed\", \n             linewidth=1, \n             colour=\"grey\") +\n  \n  geom_hline(yintercept = mean(exam_data$ENGLISH), \n             linetype=\"dashed\", \n             linewidth=1, \n             colour=\"grey\") + \n  \n  coord_cartesian(xlim = c(0, 100), \n                  ylim = c(0, 100)) + \n  theme_bw()"
  },
  {
    "objectID": "HandsonExercise/Hands-on_Ex06-VisTime.html",
    "href": "HandsonExercise/Hands-on_Ex06-VisTime.html",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "",
    "text": "By the end of this hands-on exercise you will be able create the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a horizon chart"
  },
  {
    "objectID": "HandsonExercise/Hands-on_Ex06-VisTime.html#getting-started",
    "href": "HandsonExercise/Hands-on_Ex06-VisTime.html#getting-started",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "Getting Started",
    "text": "Getting Started\n::: callout-info ## Do It Yourself Write a code chunk to check, install and launch the following R packages: scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table and tidyverse.\n\n\nShow the code\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, tidyverse, readxl, knitr, data.table)"
  },
  {
    "objectID": "HandsonExercise/Hands-on_Ex06-VisTime.html#plotting-calendar-heatmap",
    "href": "HandsonExercise/Hands-on_Ex06-VisTime.html#plotting-calendar-heatmap",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "Plotting Calendar Heatmap",
    "text": "Plotting Calendar Heatmap\nIn this section, you will learn how to plot a calender heatmap programmetically by using ggplot2 package.\n\nBy the end of this section, you will be able to:\n\nplot a calender heatmap by using ggplot2 functions and extension,\nto write function using R programming,\nto derive specific date and time related field by using base R and lubridate packages\nto perform data preparation task by using tidyr and dplyr packages.\n\n\nThe Data\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\nImporting the data\nFirst, you will use the code chunk below to import eventlog.csv file into R environment and called the data frame as attacks.\n\nattacks <- read_csv(\"data/eventlog.csv\")\n\n\n\nExamining the data structure\nIt is always a good practice to examine the imported data frame before further analysis is performed.\nFor example, kable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\n\ntz field stores time zone of the source IP address.\n\n\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\n\n\nData Preparation\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\nmake_hr_wkday <- function(ts, sc, tz) {\n  real_times <- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt <- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\nNote: ymd_hms() and hour() are from lubridate package and weekdays() is a base R function.\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels <- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks <- attacks %>%\n  group_by(tz) %>%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %>% \n  ungroup() %>% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\nNote: Beside extracting the necessary data into attacks data frame, mutate() of dplyr package is used to convert wkday and hour fields into factor so they’ll be ordered when plotting\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\nBuilding the Calendar Heatmaps\n\ngrouped <- attacks %>% \n  count(wkday, hour) %>% \n  ungroup() %>%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\nThings to learn from the code chunk: - a tibble data table called grouped is derived by aggregating the attack by wkday and hour fields. - a new field called n is derived by using group_by() and count() functions. - na.omit() is used to exclude missing value. - geom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles. - theme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot. - coord_equal() is used to ensure the plot will have an aspect ratio of 1:1. - scale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\n\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data.\n\n\nBuilding Multiple Calendar Heatmaps\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\n\n\n\nPlotting Multiple Calendar Heatmaps\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, you are required to do the followings:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country <- count(\n  attacks, source_country) %>%\n  mutate(percent = percent(n/sum(n))) %>%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nIn this step, you are required to extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 <- attacks_by_country$source_country[1:4]\ntop4_attacks <- attacks %>%\n  filter(source_country %in% top4) %>%\n  count(source_country, wkday, hour) %>%\n  ungroup() %>%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %>%\n  na.omit()\n\n\n\nPlotting Multiple Calendar Heatmaps\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "HandsonExercise/Hands-on_Ex06-VisTime.html#cycle-plot",
    "href": "HandsonExercise/Hands-on_Ex06-VisTime.html#cycle-plot",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "Cycle Plot",
    "text": "Cycle Plot\nIn this section, you will learn how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\n\nData Preparation\n\nStep 1: Data Import\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair <- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\nStep 2: Deriving month and year fields\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month <- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year <- year(ymd(air$`Month-Year`))\n\n\n\nStep 4: Extracting the target country\nNext, the code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam <- air %>% \n  select(`Vietnam`, \n         month, \n         year) %>%\n  filter(year >= 2010)\n\n\n\nStep 5: Computing year average arrivals by month\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data <- Vietnam %>% \n  group_by(month) %>%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n\nPlotting the cycle plot\nThe code chunk below is used to plot the cycle plot as shown in Slide 12/23.\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\")"
  },
  {
    "objectID": "InClassExercise/inclass03/inclass_ex03.html",
    "href": "InClassExercise/inclass03/inclass_ex03.html",
    "title": "In Class Exercise 3",
    "section": "",
    "text": "Installing and loading R packages\nTwo packages will be installed and loaded. They are tidyverse and ggiraph\n\npacman::p_load(tidyverse)\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nGetting Started  Installing and loading R packages  Two packages will be install and loaded, they are: tidyverse, ggiraph. \nAlways to load tidyverse last, to avoid any potential conflicts with tidyverse.\n\npacman::p_load(ggiraph, tidyverse)\n\n\nexam_data <- read_csv('data/Exam_data.csv', show_col_types = FALSE)\n\n\nggplot(data = exam_data,\n       aes(x = MATHS)) + geom_dotplot(dotsize = 0.5)\n\n\n\n\n\np <- ggplot(data = exam_data,\n            aes(x = MATHS)) + geom_dotplot_interactive(aes(tooltip = ID),\n                                                       stackgroups = TRUE,\n                                                       binwidth = 2,\n                                                       method = \"histodot\") + scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(ggobj = p, width_svg = 10,height_svg =  10* 0.5)"
  },
  {
    "objectID": "InClassExercise/inclass06/inclass06.html",
    "href": "InClassExercise/inclass06/inclass06.html",
    "title": "In Class Exercise 06",
    "section": "",
    "text": "Slopegraph\nhttps://public.tableau.com/app/profile/thomas.hoang8154/viz/rice_16767029061110/Sheet1\nIn order to do this on R, u need to install CGPfunction package, and an extension newggslopegraph.\nU should go and read about this package.\nBubble Plot and Animation\nhttps://public.tableau.com/app/profile/thomas.hoang8154/viz/bubbleplotpopulation/AnimatedBubblePlot\nCycle Plot\nhttps://public.tableau.com/app/profile/thomas.hoang8154/viz/InClassExercise06/Dashboard1\nSee more guides about ggplot packages for R under this site.\nhttp://exts.ggplot2.tidyverse.org/gallery\nTo draw overlapping of area graph\nhttps://nsgrantham.github.io/ggbraid/"
  }
]