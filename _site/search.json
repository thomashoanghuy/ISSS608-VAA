[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "InClassExercise/inclass03/inclass_ex03.html",
    "href": "InClassExercise/inclass03/inclass_ex03.html",
    "title": "In Class Exercise 3",
    "section": "",
    "text": "Installing and loading R packages\nTwo packages will be installed and loaded. They are tidyverse and ggiraph\n\npacman::p_load(tidyverse)\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nGetting Started  Installing and loading R packages  Two packages will be install and loaded, they are: tidyverse, ggiraph. \nAlways to load tidyverse last, to avoid any potential conflicts with tidyverse.\n\npacman::p_load(ggiraph, tidyverse)\n\n\nexam_data <- read_csv('data/Exam_data.csv', show_col_types = FALSE)\n\n\nggplot(data = exam_data,\n       aes(x = MATHS)) + geom_dotplot(dotsize = 0.5)\n\n\n\n\n\np <- ggplot(data = exam_data,\n            aes(x = MATHS)) + geom_dotplot_interactive(aes(tooltip = ID),\n                                                       stackgroups = TRUE,\n                                                       binwidth = 2,\n                                                       method = \"histodot\") + scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(ggobj = p, width_svg = 10,height_svg =  10* 0.5)"
  },
  {
    "objectID": "InClassExercise/inclass04/inclassex04.html",
    "href": "InClassExercise/inclass04/inclassex04.html",
    "title": "In-Class Exercise 4",
    "section": "",
    "text": "pacman:: p_load(plotly , DT , patchwork , ggstatsplot,  tidyverse)\n\n\nexam_data = read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nplot_ly(data = exam_data,\n        x = ~ENGLISH,\n        y = ~MATHS,\n        color = ~RACE)\n\nNo trace type specified:\n  Based on info supplied, a 'scatter' trace seems appropriate.\n  Read more about this trace type -> https://plotly.com/r/reference/#scatter\n\n\nNo scatter mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -> https://plotly.com/r/reference/#scatter-mode\n\n\n\n\n\n\n\np = ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(dotsize = 1) +\n  coord_cartesian(xlim=c(-100,100),\n                  ylim=c(-100,100))\n\nWarning in geom_point(dotsize = 1): Ignoring unknown parameters: `dotsize`\n\nggplotly(p)\n\n\n\n\n\n\nggbetweenstats(\n  data = exam_data,\n  x = GENDER, \n  y = MATHS,\n  type = \"p\",\n  messages = FALSE\n)\n\n\n\n\n\nggscatterstats(\n  data = exam_data,\n  x = MATHS, \n  y = ENGLISH,\n  marginal = TRUE\n)\n\nRegistered S3 method overwritten by 'ggside':\n  method from   \n  +.gg   ggplot2\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\npacman::p_load(readxl, performance, parameters, see)\n\n\ncar_resale <- read_xls(\"data/ToyotaCorolla.xls\", \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model       Price Age_0…¹ Mfg_M…² Mfg_Y…³     KM Quart…⁴ Weight Guara…⁵\n   <dbl> <chr>       <dbl>   <dbl>   <dbl>   <dbl>  <dbl>   <dbl>  <dbl>   <dbl>\n 1    81 TOYOTA Cor… 18950      25       8    2002  20019     100   1180       3\n 2     1 TOYOTA Cor… 13500      23      10    2002  46986     210   1165       3\n 3     2 TOYOTA Cor… 13750      23      10    2002  72937     210   1165       3\n 4     3  TOYOTA Co… 13950      24       9    2002  41711     210   1165       3\n 5     4 TOYOTA Cor… 14950      26       7    2002  48000     210   1165       3\n 6     5 TOYOTA Cor… 13750      30       3    2002  38500     210   1170       3\n 7     6 TOYOTA Cor… 12950      32       1    2002  61000     210   1170       3\n 8     7  TOYOTA Co… 16900      27       6    2002  94612     210   1245       3\n 9     8 TOYOTA Cor… 18600      30       3    2002  75889     210   1245       3\n10    44 TOYOTA Cor… 16950      27       6    2002 110404     234   1255       3\n# … with 1,426 more rows, 28 more variables: HP_Bin <chr>, CC_bin <chr>,\n#   Doors <dbl>, Gears <dbl>, Cylinders <dbl>, Fuel_Type <chr>, Color <chr>,\n#   Met_Color <dbl>, Automatic <dbl>, Mfr_Guarantee <dbl>,\n#   BOVAG_Guarantee <dbl>, ABS <dbl>, Airbag_1 <dbl>, Airbag_2 <dbl>,\n#   Airco <dbl>, Automatic_airco <dbl>, Boardcomputer <dbl>, CD_Player <dbl>,\n#   Central_Lock <dbl>, Powered_Windows <dbl>, Power_Steering <dbl>,\n#   Radio <dbl>, Mistlamps <dbl>, Sport_Model <dbl>, Backseat_Divider <dbl>, …\n\n\n\nmodel <- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\n\nComment : can use gtsummary::tbl_regression to capture and the model and translate it into data table format. # {r} # table1 = tbl_regression(model1, intercept = TRUE) #\nComment: Check for multicollinearity by diagnostic test and visualize the results using check_collinearity() of the performance package. using VIF ( variance inflation factor)\nIt will tell you give 2 predictors that have low correlation and 2 predictors that have high correlation. after that we can even use plot to check the collinearity. Above 10 >= high correlated, below 3 >= no sign of multi collinearity.\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Guarantee_Period  1.04   [1.01, 1.17]         1.02      0.97     [0.86, 0.99]\n        Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n         Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\nHigh Correlation\n\n   Term  VIF   VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n     KM 1.46 [1.37, 1.57]         1.21      0.68     [0.64, 0.73]\n Weight 1.41 [1.32, 1.51]         1.19      0.71     [0.66, 0.76]\n\n\n\ncheck_c <- check_collinearity(model)\nplot(check_c)\n\nVariable `Component` is not in your data frame :/\n\n\n\n\n\nComment: Checking Normality of the model\n\nmodel1 <- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\n\ncheck_n <- check_normality(model1)\nplot(check_n)\n\n\n\n\n\ncheck_model(model1)\n\nVariable `Component` is not in your data frame :/\n\n\n\n\n\n\nplot(parameters(model1))\n\n\n\n\n\nggcoefstats(model1, \n            output = \"plot\")\n\n\n\n\n\nmy_sum <- exam_data %>%\n  group_by(RACE) %>%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %>%\n  mutate(se=sd/sqrt(n-1))\n\n\nmy_sum\n\n# A tibble: 4 × 5\n  RACE        n  mean    sd    se\n  <chr>   <int> <dbl> <dbl> <dbl>\n1 Chinese   193  76.5  15.7  1.13\n2 Indian     12  60.7  23.4  7.04\n3 Malay     108  57.4  21.1  2.04\n4 Others      9  69.7  10.7  3.79\n\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) + \n  \n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean \n          maths score by rac\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n{r} # my_sum %>% #   ggplot(aes(x = RACE,  #              y = MATHS)) + #   stat_pointinterval() +   #   labs( #     title = \"Visualising confidence intervals of mean math score\", #     subtitle = \"Mean Point + Multiple-interval plot\") #"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "Welcome to Capybara’s homepage.\nThis is my website to practice Data Visualization and web-building skills"
  },
  {
    "objectID": "TakehomeEx/TakehomeEx01.html",
    "href": "TakehomeEx/TakehomeEx01.html",
    "title": "Takehome Exercise 1",
    "section": "",
    "text": "Singapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2022 should be used to prepare the analytical visualisation. It is available at Department of Statistics, Singapore(in short SingStat).\nLet’s examine the data.\nWe have 1 excel dataset under xlsx format. Inside we found 3 worksheets: 2022(Total) / 2022 (Male) / 2022 (Female).\nEach worksheet has 5 columns as followed:\n\n\n\n\n\n\nPlanning Areas represents the names for each planning areas in Singapore.\nSubzone further divides Planning area into small zones.\nAge group represents the age groups for population between 0 and 90, with interval of 5 years (0-4 / 5-9 / 10-14 etc…)\nType of Dwelling represents the types of housing in this census.\nTotal is the number of populations for each categories.\n\n3 worksheets, represents numbers for Male populations, Female Population and Total.\nOur tasks would be creating visualizations from these raw data. Our choices of visualization will be using Age-Sex pyramid."
  },
  {
    "objectID": "TakehomeEx/TakehomeEx01.html#data-preparation",
    "href": "TakehomeEx/TakehomeEx01.html#data-preparation",
    "title": "Takehome Exercise 1",
    "section": "Data Preparation",
    "text": "Data Preparation\nFirst, Age-sex pyramid requires data to be split into male and females. The exercise also requires to split into 9 different planning areas.\nFirst we will copy the columns which contains the total number of male ( from 2022 (Male) worksheet ) and total number of female ( from 2022 (Female)) worksheet to 2022 (Total) worksheet, adding on as 6th and 7th columns.\n\n\n\n\n\nFrom here, we can create Pivot table which includes all the data under this worksheet.\n\n\n\n\n\nSelect entire worksheet 2022 (Total) as Data source\n\n\n\n\n\nThere will be a new worksheet created, as Pivot table.\nNow we will drag Planning Area to Rows box for the Pivot table. And we will choose Total as Values box \nNow we shall right click on the Sum of Total column and Sort from Largest to smallest. We will now select 9 most populous planning areas of Singapore. We shall filter and keep these 9 areas only.\n\nNext step, we drag in Males and Females (drag and drop to Pivot table Values box) and remove the Sums of Total from this Values box.\nWe will also add in the Age Group, under Rows box.\n\nWe will have a table of 9 most populous areas in Singapore, and their age-group smaller breakdown.\n\nWe will filter out the Total from these age group breakdown. (Because the total for each areas are already in bolden first row, so we don’t need this last row of Total anymore.\nWe shall copy this table and paste-special (values only) to a new worksheet.\n\nInsert a new column in between Rows Label and Sums of Male.\nCopy the age group over, we will separate: First column is only for name of Planning Areas ( Bedok, Choa Chu Kang, Hougang etc…) and second column will be only for Age Group."
  },
  {
    "objectID": "TakehomeEx/TakehomeEx01.html#our-final-worksheet-we-will-have-a-similar-worksheet-like-this-under-worksheet-sheet1",
    "href": "TakehomeEx/TakehomeEx01.html#our-final-worksheet-we-will-have-a-similar-worksheet-like-this-under-worksheet-sheet1",
    "title": "Takehome Exercise 1",
    "section": "Our final worksheet, we will have a similar worksheet like this ( under worksheet Sheet1)",
    "text": "Our final worksheet, we will have a similar worksheet like this ( under worksheet Sheet1)"
  },
  {
    "objectID": "TakehomeEx/TakehomeEx01.html#dashboard-building",
    "href": "TakehomeEx/TakehomeEx01.html#dashboard-building",
    "title": "Takehome Exercise 1",
    "section": "DASHBOARD BUILDING",
    "text": "DASHBOARD BUILDING\nOpen new Tableau window. Save and name it as your project.\nWe can drag the xlsx excel data into this Tableau window.\nDrag Sheet1 into the middle (this is the final data table above after data transformation from previous steps). We shall take this as our datasource.\nClick on Sheet 1 and we will create the first Tableau Sheet\n\nWe shall put drag these items to Columns: Sums of MALE , Sums of FEMALE and Rows: Planning Area\n\nNext, right click on one of the Axis and EDIT AXIS\n\nWe will tick the Reverse options, as well as rename the axis to “Male Population”\n\nWe shall repeat the same for Female side. (but do not tick the Reverse option).\nWe shall then right click Null value to exclude them from the filter\n\nFinally, we will have a pyramid graph, similar to this\n\n\n\n\n\nWe shall right on the Sheet 1, and duplicate this worksheet 9 times, one for each other areas.\nWe shall rename each worksheets as per each of the planning areas ( Bedok, Choa Chu Kang, Hougang etc…)\nThis is already a pyramid graph of Singapore populations for 9 most populous areas, but we still need to break down in term of age group.\n\nWe select Bedok sheet\nRight click on Filters of Planning Areas > Edit filters\n\nFor example, if this is worksheet for Bedok, we can exclude other areas.\n\nNext, we drag Age Group into Rows.\n\nRight click on Age Group > Filter > Exclude Total\nWe will have a pyramid graph for Bedok population only: Depict populations between Male and Female, with subsets of each age groups for Bedok areas only.\n\nNext is aesthetics, where we have to input colours to make things more distinctive.\nThe recommendation would be one half (Male) would be warm and light color, while the other half should carry darker and cold color.\n\nWe repeat the same steps above for all 9 planning areas. Remember to maintain the same color codes / formats for all 9 areas."
  },
  {
    "objectID": "TakehomeEx/TakehomeEx01.html#lastly-we-can-building-dashboard.",
    "href": "TakehomeEx/TakehomeEx01.html#lastly-we-can-building-dashboard.",
    "title": "Takehome Exercise 1",
    "section": "Lastly, we can building Dashboard.",
    "text": "Lastly, we can building Dashboard.\nCreate new dashboard\n\nWe choose Floating as the setting and choose Vertical objects\n\nWe divide dashboard into 9 evenly horizontal rectangle containers. Next we drag each of the Sheets into each of these container.\n\n\nRemember to change Standard to Entire view to see entire graph.\nAlso click on Device Preview and view as Large Desktop Monitor (2560 x 1440) And click on Size ( default is Fixed) and change to Automatic.\nAfter dragging each planning areas into the container. Remove the labels and ledgers ( Plannings Areas, Sum of Male and Sums of Females.\nPlay around with the 9 planning areas (alignments of lines and borders, colours etc..)"
  },
  {
    "objectID": "TakehomeEx/TakehomeEx01.html#final-results-would-look-similar-to-this.",
    "href": "TakehomeEx/TakehomeEx01.html#final-results-would-look-similar-to-this.",
    "title": "Takehome Exercise 1",
    "section": "Final results would look similar to this.",
    "text": "Final results would look similar to this."
  },
  {
    "objectID": "TakehomeEx/TakehomeEx01.html#publishing-dashboard",
    "href": "TakehomeEx/TakehomeEx01.html#publishing-dashboard",
    "title": "Takehome Exercise 1",
    "section": "Publishing Dashboard",
    "text": "Publishing Dashboard\nFinally, we can go to Data / Sheet1 / Extract Data\nAfter data extraction (saving Tableau working as .hyper file), we can go to Server > Tableau Public > Save to Tableau Public.\nIf you have logged in to your Tableau public account, this will be uploaded as a new Viz under your profile.\nYou can view my published Viz under this link\nSingapore Population Distribution"
  },
  {
    "objectID": "TakehomeEx/TakehomeEx01.html#summary",
    "href": "TakehomeEx/TakehomeEx01.html#summary",
    "title": "Takehome Exercise 1",
    "section": "SUMMARY",
    "text": "SUMMARY"
  },
  {
    "objectID": "TakehomeEx/TakehomeEx01.html#commentaries-on-the-data",
    "href": "TakehomeEx/TakehomeEx01.html#commentaries-on-the-data",
    "title": "Takehome Exercise 1",
    "section": "Commentaries on the Data",
    "text": "Commentaries on the Data\nThere is a general assumption about Singapore population: Singapore is having an aging population. The general trend observable from the pyramid graphs of 9 different planning areas in Singapore show that they are all middle heavy (meaning the highest segment of population are among the working adults between 25- to 60 years old).\nWhile it is natural that the bottom of these pyramid graph, which represent the elderly populations, are small, due to death, it is indeed an evident of an aging population when most of the top portions of the pyramids are also small. This shows that Singaporean at family-planning age (at the age 25-60 years old) , are not having children, hence the low fertility rate and a smaller tops of the pyramids\nA closer look at different planning areas, can give us some patterns on different geographical distributions as well. Generally, other 7 out of 9 areas in this dashboard, for the age between 0 and 20, the younger, the smaller are the population numbers, while the adolescent population are largest among pre-adults’ population. Except Punggol and Sengkang, these 2 areas see the highest percentage of populations of children age, when compared to the rest of population of the area. This may suggest that Sengkang and Punggol are two areas where there are many young families / couples are having children.\nThe gender distribution of Singapore’s population is relatively balanced, However, there are slight variations in the gender distribution among different age groups. For example, among children aged 0-14, there are slightly more males than females. However, among adults aged 15-64, there are slightly more females than males. And among older adults aged 75 and above, there are more females than males. This is because female tend to have higher life expectancy than male.\nFurther breakdown by planning areas, Punggol and Sengkang are 2 areas with highest portion of populations among the 25-40 years old, millennial prime working populations, compared to the other age groups in the same areas. This means the average ages of population among these 2 areas would be lower, compared to other matured estates.\nIn conclusion, while some of areas of Singapore are consisting of younger populations and children / teenage populations, overall, Singapore is still foreseen to encounter an aging population. With majority of graphs are middle heavy ( the working adults age between 25-60), these segment of population will eventually grow older and move to older age groups, while the smaller top populations of children and teenagers are too small to replace the current working adult population. If this is not addressed urgently by the government, this will lead to many social and economic and healthcare problems for the country within next few decades."
  },
  {
    "objectID": "TakehomeEx/TakehomeEx01.html#about-this-site.",
    "href": "TakehomeEx/TakehomeEx01.html#about-this-site.",
    "title": "Takehome Exercise 1",
    "section": "About this site.",
    "text": "About this site.\nThis is capybara first site that help me start learning Data visualization with many tools\n\nData Preparation and Cleaning with Excel\nData Visualization by Tableau\nWebsite Design by HTML and R Studio tools to create , render , commit onto Github and subsequently publishing on Netlify"
  },
  {
    "objectID": "TakehomeEx/TakehomeEx02.html",
    "href": "TakehomeEx/TakehomeEx02.html",
    "title": "TakeHome Exercise 2",
    "section": "",
    "text": "In the first task, we are supposed to create Age-sex Pyramid to cover 9 planning areas of Singapore in term of Male/ Female and the age group.\nBelow is one of the DataViz that was created by a classmate.\nhttps://public.tableau.com/app/profile/ruipeng.wang/viz/take_home_01/Dashboard1?fbclid=IwAR1xjLcdtI9B6IQsXvE8DeuHGT0Xe1sL20M6RPAZ2gvhEV_hLizpZ9QdADg\n\nOriginal DataViz\nCritiques:\n\nClarity: The viz was created for 9 planning areas with 9 different populations. However, they use to same absolute scales in terms of number of people. Therefore, the areas with small number of populations ( Downtown Core and Outram) when putting in the same x-axis scale as other areas, does not have high enough number of people, to show case the distributions as Age-sex pyramid.\nClarity Some age groups have data labels ( number of people in that age group), however many age groups do not have any data labels. It looks like the data label are randomly assigned.\nAesthetics Age-sex pyramid of 9 area, should not occupy such big area of spaces (taking up entire horizontal dataviz). There are other designs that can save spaces for other graphs / charts that will portray more information from the data."
  },
  {
    "objectID": "TakehomeEx/TakehomeEx02.html#age-sex-pyramid-graph-for-bedok",
    "href": "TakehomeEx/TakehomeEx02.html#age-sex-pyramid-graph-for-bedok",
    "title": "TakeHome Exercise 2",
    "section": "AGE-SEX PYRAMID GRAPH FOR BEDOK",
    "text": "AGE-SEX PYRAMID GRAPH FOR BEDOK\nWe use fill = bedok_df$ID (the new column added) is to separate the 2 genders.\n\nggplot(bedok_df,\n       aes( x = bedok_df$`Population Perc` , y = bedok_df$`AGE GROUP` , fill = bedok_df$ID ))+\n  geom_bar(stat = \"identity\") +\n  ggtitle(\"Distribution of Bedok\")+\n  ylab(\"AGE GROUP\")+\n  xlab(\"Percentage of Area Population\") +\n  labs(fill = \"Gender\")+\n  scale_x_continuous(breaks = scales::pretty_breaks(n = 10))\n\nWarning: Use of `` bedok_df$`Population Perc` `` is discouraged.\nℹ Use `Population Perc` instead.\n\n\nWarning: Use of `` bedok_df$`AGE GROUP` `` is discouraged.\nℹ Use `AGE GROUP` instead.\n\n\nWarning: Use of `bedok_df$ID` is discouraged.\nℹ Use `ID` instead.\n\n\n\n\n\nFinally we have created a Age-Sex pyramid, using percentage of the Population of the area, rather than their absolute numbers.\nAs such, even with the area of low population (like Outram or Downtown Core) , each age groups will still be better visualized using percentage of its own population.\nWe can repeat this same steps for any planning areas in our original data."
  },
  {
    "objectID": "TakehomeEx/TakehomeEx02.html#pyramid-graph-for-9-planning-areas-population-by-gender",
    "href": "TakehomeEx/TakehomeEx02.html#pyramid-graph-for-9-planning-areas-population-by-gender",
    "title": "TakeHome Exercise 2",
    "section": "PYRAMID GRAPH FOR 9 PLANNING AREAS POPULATION, BY GENDER",
    "text": "PYRAMID GRAPH FOR 9 PLANNING AREAS POPULATION, BY GENDER\nWith the combined dataframe, we can draw the pyramid graph using the ggplot2 now\n\nggplot(sg_pop,\n       aes( x = Population , y = Area , fill = Gender))+\n  geom_bar(stat = \"identity\") +\n  ggtitle(\"SINGAPORE POPULATION DISTRIBUTION\")+\n  ylab(\"AREA\")+\n  xlab(\"Population\") +\n  labs(fill = \"Gender\")\n\n\n\n  scale_x_continuous(labels = scales::comma_format(big.mark = ',' , decimal.mark = '.') , breaks = scales::pretty_breaks(n = 5))\n\n<ScaleContinuousPosition>\n Range:  \n Limits:    0 --    1\n\n\nAs you can see, Outram and Downtown Core have the lowest number of population among the 9 chosen area. While Woodlands have the largest population."
  },
  {
    "objectID": "TakehomeEx/TakehomeEx03.html",
    "href": "TakehomeEx/TakehomeEx03.html",
    "title": "Take Home Exercise 03",
    "section": "",
    "text": "In this take-home exercise, we will study the patterns of the resale prices of public housing property by residential towns and estates in Singapore by using appropriate analytical visualisation techniques learned in Lesson 4: Fundamentals of Visual Analytics.\nFor the purpose of this study, the focus should be on 3-ROOM, 4-ROOM and 5-ROOM types."
  },
  {
    "objectID": "TakehomeEx/TakehomeEx03.html#two-sample-mean-test",
    "href": "TakehomeEx/TakehomeEx03.html#two-sample-mean-test",
    "title": "TakehomeEx03",
    "section": "Two sample mean test:",
    "text": "Two sample mean test:\nLet’s pull out data for 3 types of flats, 3 ROOM / 4 ROOM and 5 ROOM\n\ndf_345 <- subset(overall_data, flat_type %in% c(\"3 ROOM\", \"4 ROOM\", \"5 ROOM\"))\n\n\ndf_345$price_per_sqm = df_345$`resale_price` / df_345$floor_area_sqm\ntail(df_345)\n\n# A tibble: 6 × 12\n  month   town   flat_type block stree…¹ store…² floor…³ flat_…⁴ lease…⁵ remai…⁶\n  <chr>   <chr>  <chr>     <chr> <chr>   <chr>     <dbl> <chr>     <dbl> <chr>  \n1 2023-02 YISHUN 4 ROOM    720   YISHUN… 01 TO …      84 Simpli…    1985 61 yea…\n2 2023-02 YISHUN 4 ROOM    867   YISHUN… 04 TO …      84 Simpli…    1988 64 yea…\n3 2023-02 YISHUN 5 ROOM    347A  YISHUN… 13 TO …     112 DBSS       2013 89 yea…\n4 2023-02 YISHUN 5 ROOM    785   YISHUN… 10 TO …     121 Improv…    1988 64 yea…\n5 2023-02 YISHUN 5 ROOM    336C  YISHUN… 07 TO …     112 Improv…    2015 91 yea…\n6 2023-02 YISHUN 5 ROOM    513D  YISHUN… 07 TO …     120 3Gen       2018 94 yea…\n# … with 2 more variables: resale_price <dbl>, price_per_sqm <dbl>, and\n#   abbreviated variable names ¹​street_name, ²​storey_range, ³​floor_area_sqm,\n#   ⁴​flat_model, ⁵​lease_commence_date, ⁶​remaining_lease\n\n\n\np2 <- ggbetweenstats(\n  data = df_345,\n  x = flat_type, \n  y = price_per_sqm,\n  type = \"np\",\n  messages = FALSE\n)\np2"
  },
  {
    "objectID": "InClassExercise/inclass05/inclass05.html",
    "href": "InClassExercise/inclass05/inclass05.html",
    "title": "In-Class Exercise 05",
    "section": "",
    "text": "pacman::p_load(corrplot, tidyverse, ggstatsplot)\n\n#IMPORTING AND PREPARING THE DATASET#\n\nwine = read_csv(\"data/wine_quality.csv\")\n\nRows: 6497 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): type\ndbl (12): fixed acidity, volatile acidity, citric acid, residual sugar, chlo...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\npairs(wine[,1:11])\n\n\n\n\n\n#| fig-dpi: 75\n#these will affect the placement of the graph on the quarto page (maximum is 14)\n#fig dpi is default 30, if increase sharpness by increase to 75 or 100\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11, \n    ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are no significant at p < 0.05\"\n) \n\n\n\n\n\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)\n\n\n\n\n\nwine.cor = cor(wine[,1:11])\n\n\ncorrplot(wine.cor)\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\",\n         diag = FALSE,\n         tl.col = \"black\")\n\n\n\n\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n##Combining corrgram with the significant test##\nWith corrplot package, we can use the cor.mtest() to compute the p-values and confidence interval for each pair of variables.\n\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\n\nWe can then use the p.mat argument of corrplot function as shown in the code chunk below.\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)\n\n\n\n\n###Reorder a corrgram By default, the order of attributes of a corrgram is sorted according to the correlation matrix (i.e. “original”). The default setting can be over-write by using the order argument of corrplot(). Currently, corrplot package support four sorting methods, they are:\n“AOE” is for the angular order of the eigenvectors. “FPC” for the first principal component order. “hclust” for hierarchical clustering order, and “hclust.method” for the agglomeration method to be used. “hclust.method” should be one of “ward”, “single”, “complete”, “average”, “mcquitty”, “median” or “centroid”. “alphabet” for alphabetical order.\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\npop_data <- read_csv(\"data/respopagsex2000to2018_tidy.csv\")  \n\nRows: 108126 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): PA, SZ, AG\ndbl (2): Year, Population\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\ntail(pop_data)\n\n# A tibble: 6 × 5\n  PA     SZ          AG         Year Population\n  <chr>  <chr>       <chr>     <dbl>      <dbl>\n1 Yishun Yishun West AGE85over  2013        400\n2 Yishun Yishun West AGE85over  2014        450\n3 Yishun Yishun West AGE85over  2015        510\n4 Yishun Yishun West AGE85over  2016        560\n5 Yishun Yishun West AGE85over  2017        590\n6 Yishun Yishun West AGE85over  2018        620\n\n\n\nagpop_mutated <- pop_data %>%\n  mutate(`Year` = as.character(Year))%>%\n  spread(AG, Population)%>%\n  mutate(YOUNG = rowSums(.[4:8]))%>%\n  mutate(ACTIVE = rowSums(.[9:16]))  %>%\n  mutate(OLD = rowSums(.[17:21])) %>%\n  mutate(TOTAL = rowSums(.[22:24])) %>%\n  filter(Year == 2018)%>%\n  filter(TOTAL > 0)\n\n\nagpop_mutated\n\n# A tibble: 234 × 25\n   PA        SZ    Year  AGE0-…¹ AGE05…² AGE10…³ AGE15…⁴ AGE20…⁵ AGE25…⁶ AGE30…⁷\n   <chr>     <chr> <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 Ang Mo K… Ang … 2018      180     270     320     300     260     300     270\n 2 Ang Mo K… Chen… 2018     1060    1080    1080    1260    1400    1880    1940\n 3 Ang Mo K… Chon… 2018      900     900    1030    1220    1380    1760    1830\n 4 Ang Mo K… Kebu… 2018      720     850    1010    1120    1230    1460    1330\n 5 Ang Mo K… Semb… 2018      220     310     380     500     550     500     300\n 6 Ang Mo K… Shan… 2018      550     630     670     780     950    1080     990\n 7 Ang Mo K… Tago… 2018      260     340     430     500     640     690     440\n 8 Ang Mo K… Town… 2018      830     930     930     860    1020    1400    1350\n 9 Ang Mo K… Yio … 2018      160     160     220     260     350     340     230\n10 Ang Mo K… Yio … 2018      810    1070    1300    1450    1500    1590    1390\n# … with 224 more rows, 15 more variables: `AGE35-39` <dbl>, `AGE40-44` <dbl>,\n#   `AGE45-49` <dbl>, `AGE50-54` <dbl>, `AGE55-59` <dbl>, `AGE60-64` <dbl>,\n#   `AGE65-69` <dbl>, `AGE70-74` <dbl>, `AGE75-79` <dbl>, `AGE80-84` <dbl>,\n#   AGE85over <dbl>, YOUNG <dbl>, ACTIVE <dbl>, OLD <dbl>, TOTAL <dbl>, and\n#   abbreviated variable names ¹​`AGE0-4`, ²​`AGE05-9`, ³​`AGE10-14`, ⁴​`AGE15-19`,\n#   ⁵​`AGE20-24`, ⁶​`AGE25-29`, ⁷​`AGE30-34`\n\n\n\nagpop_mutated %>%\nselect(\"PA\" , \"SZ\" , \"YOUNG\" , \"ACTIVE\" , \"OLD\" , \"TOTAL\")\n\n# A tibble: 234 × 6\n   PA         SZ                     YOUNG ACTIVE   OLD TOTAL\n   <chr>      <chr>                  <dbl>  <dbl> <dbl> <dbl>\n 1 Ang Mo Kio Ang Mo Kio Town Centre  1330   2770   730  4830\n 2 Ang Mo Kio Cheng San               5880  16970  5480 28330\n 3 Ang Mo Kio Chong Boon              5430  15700  5960 27090\n 4 Ang Mo Kio Kebun Bahru             4930  13300  4780 23010\n 5 Ang Mo Kio Sembawang Hills         1960   3620  1200  6780\n 6 Ang Mo Kio Shangri-La              3580   9600  3360 16540\n 7 Ang Mo Kio Tagore                  2170   4650  1300  8120\n 8 Ang Mo Kio Townsville              4570  12580  4800 21950\n 9 Ang Mo Kio Yio Chu Kang East       1150   2410   640  4200\n10 Ang Mo Kio Yio Chu Kang West       6130  14580  4270 24980\n# … with 224 more rows\n\n\n\npacman::p_load(ggtern, plotly, tidyverse)\n\n\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) + geom_point()+\n  labs(title = \"Population Structure, 2015\")+\n  theme_rgbg()\n\n\n\n\n##If you write it in basic plot_ly, the graph will be more interactive interface compared to using ggtern##\n\nlabel <- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\naxis <- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes <- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %>%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )\n\nNo scatterternary mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -> https://plotly.com/r/reference/#scatter-mode\n\n\n\n\n\n\n\npacman::p_load(seriation, dendextend, heatmaply, tidyverse)\n\n\nwh <- read_csv(\"data/WHData-2018.csv\")\n\nRows: 156 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): Country, Region\ndbl (10): Happiness score, Whisker-high, Whisker-low, Dystopia, GDP per capi...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nrow.names(wh) <- wh$Country\n\nWarning: Setting row names on a tibble is deprecated.\n\n\n##Purpose of the above step is to take the column Country TO MAKE THEM the names of the rows in the dataframe, instead of automatic 1,2,3,4 numeric name##\n\nwh\n\n# A tibble: 156 × 12\n   Country        Region Happi…¹ Whisk…² Whisk…³ Dysto…⁴ GDP p…⁵ Socia…⁶ Healt…⁷\n * <chr>          <chr>    <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 Albania        Centr…    4.59    4.70    4.48    1.46   0.916   0.817   0.79 \n 2 Bosnia and He… Centr…    5.13    5.22    5.04    1.88   0.915   1.08    0.758\n 3 Bulgaria       Centr…    4.93    5.02    4.84    1.22   1.05    1.52    0.712\n 4 Croatia        Centr…    5.32    5.40    5.24    1.77   1.12    1.16    0.737\n 5 Czech Republic Centr…    6.71    6.78    6.64    2.49   1.23    1.49    0.854\n 6 Estonia        Centr…    5.74    5.82    5.66    1.46   1.2     1.53    0.737\n 7 Hungary        Centr…    5.62    5.70    5.54    1.97   1.17    1.40    0.732\n 8 Kosovo         Centr…    5.66    5.76    5.57    2.26   0.855   1.23    0.578\n 9 Latvia         Centr…    5.93    6.00    5.86    2.14   1.15    1.45    0.671\n10 Lithuania      Centr…    5.95    6.04    5.87    2.13   1.20    1.53    0.716\n# … with 146 more rows, 3 more variables: `Freedom to make life choices` <dbl>,\n#   Generosity <dbl>, `Perceptions of corruption` <dbl>, and abbreviated\n#   variable names ¹​`Happiness score`, ²​`Whisker-high`, ³​`Whisker-low`,\n#   ⁴​Dystopia, ⁵​`GDP per capita`, ⁶​`Social support`, ⁷​`Healthy life expectancy`\n\n\n\nwh1 <- dplyr::select(wh, c(3, 7:12))\nwh_matrix <- data.matrix(wh)\n\n##wh_matrix is MATRIX, not a data table as per original wh dataframe anymore. We can only draw heatmap on matrix, rather than plain dataframe.##\n###We use heatmaply to draw this matrix into heatmap, notice that the graph is interactive!###\n\nwh_heatmap <- heatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\nwh_heatmap\n\n\n\n\n\n###Note: Normalising method### When variables in the data comes from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations. This preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\nOn other hands, ###Note: Percentising method### 1) This is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank. 2) This is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile. 3) The benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n#Clustering Algo# heatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:\n##1) Manual approach## In the code chunk below, the heatmap is plotted by using hierachical clustering algorithm with “Euclidean distance” and “ward.D” method.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n##2) Statistical approach## ###First, we have to find best clustering method should be used on this dataset### We use dend_expend for this\n\nwh_d <- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nAs you can see, average method is the most optimum with the highest score 0.67\n###Second, we need to find what is the optimal number of cluster### We should use find_k() for this step\n\nwh_clust <- hclust(wh_d, method = \"average\")\nnum_k <- find_k(wh_clust)\nplot(num_k)\n\n\n\n\nAs we can see, the optimal k = 3.\nWith that, we can use this statistical analysis result to do the code\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)\n\n\n\n\n\n#Finishing# In the code chunk below the following arguments are used:\nk_row is used to produce 5 groups. margins is used to change the top margin to 60 and row margin to 200. fontsizw_row and fontsize_col are used to change the font size for row and column labels to 4. main is used to write the main title of the plot. xlab and ylab are used to write the x-axis and y-axis labels respectively.\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )\n\n\n\n\n\n##Plotting Static Parallel Coordinates Plot##\n\npacman::p_load(GGally, parallelPlot, tidyverse)\n\n\nggparcoord(data = wh, \n           columns = c(7:12))\n\n\n\n\n##Plotting Static Parallel Coordinates with BOX PLOT##\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")\n\nWarning: The following aesthetics were dropped during statistical transformation: colour\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\n##DRAWING PARALLEL COORDINATE WITH PARRALLEL PLOT USING parallelplot, will allow BRUSHING (INTERACTIVE)## Mean you can choose a column (for example Happiness Score) and we can highlight a portion of that column, and it will make highlight the rest of the data.\nWe can see what whether people with highest happiness score, such as 8 / 7.5 / 7, whether they have highest GDP, highest SOCIAL SUPPORT or HEALTHY LIFE EXPECTATION\n\nwh <- wh %>%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250)\n\n\n\n\n\n\nparallelPlot(wh,\n             rotateTitle = TRUE)\n\n\n\n\n\n\nhistoVisibility <- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)"
  },
  {
    "objectID": "TakehomeEx/TakehomeEx03.html#room-average-resale-prices-for-ang-mo-kio",
    "href": "TakehomeEx/TakehomeEx03.html#room-average-resale-prices-for-ang-mo-kio",
    "title": "TakehomeEx03",
    "section": "4-ROOM average resale prices for Ang Mo Kio",
    "text": "4-ROOM average resale prices for Ang Mo Kio\n\nfour_roomdf_amk1 = four_roomdf_amk[c(\"month\"  , \"price_per_sqm\" )]\namk_monthly_avg2 = four_roomdf_amk1 %>%\ngroup_by(month) %>%\nsummarise(average_price_sqm2 = mean(price_per_sqm))\n\n\np1 = ggplot(amk_monthly_avg2, aes(x= amk_monthly_avg2$month, y=amk_monthly_avg2$average_price_sqm2 , group = 1)) +\n  geom_smooth() + geom_point()+\n  theme(axis.text.x=element_text(angle=90, hjust=1))+\n  xlab(\"Month\")+ylab(\"Average Price 4 room flat in Ang Mo Kio\")\n\np1\n\nWarning: Use of `amk_monthly_avg2$month` is discouraged.\nℹ Use `month` instead.\n\n\nWarning: Use of `amk_monthly_avg2$average_price_sqm2` is discouraged.\nℹ Use `average_price_sqm2` instead.\n\n\nWarning: Use of `amk_monthly_avg2$month` is discouraged.\nℹ Use `month` instead.\n\n\nWarning: Use of `amk_monthly_avg2$average_price_sqm2` is discouraged.\nℹ Use `average_price_sqm2` instead.\n\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'"
  },
  {
    "objectID": "TakehomeEx/TakehomeEx03.html#room-average-resale-prices-for-ang-mo-kio-1",
    "href": "TakehomeEx/TakehomeEx03.html#room-average-resale-prices-for-ang-mo-kio-1",
    "title": "TakehomeEx03",
    "section": "5-ROOM average resale prices for Ang Mo Kio",
    "text": "5-ROOM average resale prices for Ang Mo Kio\n\nfive_roomdf_amk1 = five_roomdf_amk[c(\"month\"  , \"price_per_sqm\" )]\namk_monthly_avg3 = five_roomdf_amk1 %>%\ngroup_by(month) %>%\nsummarise(average_price_sqm2 = mean(price_per_sqm))\n\n\np2 = ggplot(amk_monthly_avg3, aes(x= amk_monthly_avg3$month, y=amk_monthly_avg3$average_price_sqm2 , group = 1)) +\n  geom_smooth() + geom_point()+\n  theme(axis.text.x=element_text(angle=90, hjust=1))+\n  xlab(\"Month\")+ylab(\"Average Price 5 room flat in Ang Mo Kio\")\n\np2\n\nWarning: Use of `amk_monthly_avg3$month` is discouraged.\nℹ Use `month` instead.\n\n\nWarning: Use of `amk_monthly_avg3$average_price_sqm2` is discouraged.\nℹ Use `average_price_sqm2` instead.\n\n\nWarning: Use of `amk_monthly_avg3$month` is discouraged.\nℹ Use `month` instead.\n\n\nWarning: Use of `amk_monthly_avg3$average_price_sqm2` is discouraged.\nℹ Use `average_price_sqm2` instead.\n\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\nAs you can see, in Ang Mo Kio, 4 rooms and 5 room types of flats have similar trends, from 2017, it was on the downtrend up til 2019 before started picking up and increased until current year 2023.\nThe difference are, for 4 room and 5 rooms units, there are some months where there are huge outliers, and the standard deviation away from the trend-line are much bigger compared to 3-Room type of flats. This means for 4 rooms and 5 room types of flats, there are certain transactions that are priced at much higher prices compared to the group’s monthly average.\nThe above chunks of code can be applied to any other areas in Singapore to derive time series analysis on average prices of resales flat in Singapore."
  },
  {
    "objectID": "TakehomeEx/TakehomeEx03.html#lease-remains-number-of-years-versus-averge-price-per-sqm",
    "href": "TakehomeEx/TakehomeEx03.html#lease-remains-number-of-years-versus-averge-price-per-sqm",
    "title": "TakehomeEx03",
    "section": "LEASE REMAINS NUMBER OF YEARS VERSUS AVERGE PRICE PER SQM",
    "text": "LEASE REMAINS NUMBER OF YEARS VERSUS AVERGE PRICE PER SQM\n\np3 <-ggplot(df_345,\n       aes(x = lease_remains,\n           y = price_per_sqm ,\n           colour = flat_type)) +\n  geom_point() +\n  labs(title = \"Resale price per square meter verus remaining lease years\",\n       x = \"Remaining Lease (Years)\",\n       y = \"Resale price ($psm)\",\n       fill =\"Flat type\",\n       caption = \"Month of 2022: {frame_time}\")+\n  geom_smooth(method=\"lm\",\n              se = FALSE,\n              color = \"white\",\n              formula = y ~ x)+\n  facet_grid(flat_type ~ .)+\n  transition_time(df_345$month_no) + ease_aes('linear')\n  \nanimate(p3, nframes = 10 , fps = 0.5)\n\nWarning: Removed 10927 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 1202 rows containing missing values (`geom_point()`).\nRemoved 1202 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 760 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 744 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 757 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 917 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 1169 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 1136 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 1002 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 747 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 841 rows containing missing values (`geom_point()`).\n\n\n\n\n\nThe above charts show us that the average prices of HDB units in Singapore, it is not necessary that the longer remaining of the lease, the higher the resale prices of the unit. The units with the highest price per square meter, are those with remaining lease between 87-92 years. While the lowest in resale prices per square meter are around 67 or 77 years of leases."
  },
  {
    "objectID": "TakehomeEx/TakehomeEx03.html#averge-price-per-sqm-versus-lease-remains-number-of-years",
    "href": "TakehomeEx/TakehomeEx03.html#averge-price-per-sqm-versus-lease-remains-number-of-years",
    "title": "Take Home Exercise 03",
    "section": "AVERGE PRICE PER SQM versus LEASE REMAINS NUMBER OF YEARS",
    "text": "AVERGE PRICE PER SQM versus LEASE REMAINS NUMBER OF YEARS\n\np3 <-ggplot(df_345,\n       aes(x = lease_remains,\n           y = price_per_sqm ,\n           colour = flat_type)) +\n  geom_point() +\n  labs(title = \"Resale price per square meter verus Remaining lease years\",\n       x = \"Remaining Lease (Years)\",\n       y = \"Resale price ($psm)\",\n       fill =\"Flat type\",\n       caption = \"Month From 2017 - 2023: {frame_time}\")+\n  geom_smooth(method=\"lm\",\n              se = FALSE,\n              color = \"yellow\",\n              formula = y ~ x)+\n  facet_grid(flat_type ~ .)+\n  theme(legend.position = \"none\")+\n  transition_time(df_345$month_no) + ease_aes('linear')\n  \nanimate(p3, nframes = 10 , fps = 0.5)\n\nWarning: Removed 10927 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 1202 rows containing missing values (`geom_point()`).\nRemoved 1202 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 760 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 744 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 757 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 917 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 1169 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 1136 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 1002 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 747 rows containing missing values (`geom_point()`).\n\n\nWarning: Removed 841 rows containing missing values (`geom_point()`).\n\n\n\n\n\nThe above charts show us that the average prices of HDB units in Singapore against the remaining lease years of the units for at least 3 groups, the 3-ROOM, 4 ROOM and 5 ROOM. While the yellow line shows that there are certain truth when the longer the remaining lease are, the higher the average prices of the units.\nHowever the steepness of the yellow line shows that the correlation is not really extreme, across 40 years between 50 years remaining units and 95 years units, the average price per square meter does not increase that much. In other words, this shows that even average values of HDB does not depreciate due to the lease running down."
  },
  {
    "objectID": "TakehomeEx/TakehomeEx03.html#room-average-resale-prices",
    "href": "TakehomeEx/TakehomeEx03.html#room-average-resale-prices",
    "title": "Take Home Exercise 03",
    "section": "4-ROOM average resale prices",
    "text": "4-ROOM average resale prices\n\nfour_roomdf1 = four_roomdf[c(\"month\"  , \"price_per_sqm\" )]\nfourrooms_monthly_avg2 = four_roomdf1 %>%\ngroup_by(month) %>%\nsummarise(average_price_sqm2 = mean(price_per_sqm))\n\n\np1 = ggplot(fourrooms_monthly_avg2, aes(x= fourrooms_monthly_avg2$month, y=fourrooms_monthly_avg2$average_price_sqm2 , group = 1)) +\n  geom_smooth() + geom_point()+\n  theme(axis.text.x=element_text(angle=90, hjust=1))+\n  xlab(\"Month\")+ylab(\"Average Price 4 room flat\")\n\np1\n\nWarning: Use of `fourrooms_monthly_avg2$month` is discouraged.\nℹ Use `month` instead.\n\n\nWarning: Use of `fourrooms_monthly_avg2$average_price_sqm2` is discouraged.\nℹ Use `average_price_sqm2` instead.\n\n\nWarning: Use of `fourrooms_monthly_avg2$month` is discouraged.\nℹ Use `month` instead.\n\n\nWarning: Use of `fourrooms_monthly_avg2$average_price_sqm2` is discouraged.\nℹ Use `average_price_sqm2` instead.\n\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'"
  },
  {
    "objectID": "TakehomeEx/TakehomeEx03.html#room-average-resale-prices-1",
    "href": "TakehomeEx/TakehomeEx03.html#room-average-resale-prices-1",
    "title": "Take Home Exercise 03",
    "section": "5-ROOM average resale prices",
    "text": "5-ROOM average resale prices\n\nfive_roomdf1 = five_roomdf[c(\"month\"  , \"price_per_sqm\" )]\nfiveroom_monthly_avg3 = five_roomdf1 %>%\ngroup_by(month) %>%\nsummarise(average_price_sqm2 = mean(price_per_sqm))\n\n\nfiveroom_monthly_avg4 <- fiveroom_monthly_avg3 %>%\n  separate(month,\n           into = c(\"year_no\", \"month_no\"),\n           sep = \"-\",\n           convert = TRUE)\n\n\np2 = ggplot(fiveroom_monthly_avg4, aes(x= fiveroom_monthly_avg3$month, y=fiveroom_monthly_avg3$average_price_sqm2 , group = 1)) +\n  geom_smooth() + geom_point()\n  theme(axis.text.x=element_text(angle=90, hjust=1))+\n  xlab(\"Month\")+ylab(\"Average Price 5 room flat\")\n\nList of 3\n $ axis.text.x:List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 1\n  ..$ vjust        : NULL\n  ..$ angle        : num 90\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi FALSE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ x          : chr \"Month\"\n $ y          : chr \"Average Price 5 room flat\"\n - attr(*, \"class\")= chr [1:2] \"theme\" \"gg\"\n - attr(*, \"complete\")= logi FALSE\n - attr(*, \"validate\")= logi TRUE\n\nanimate (p2 + transition_time(fiveroom_monthly_avg4$month_no) + labs(title = \"Month from 2017 - 2023: {frame_time}\")  )\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric =\nparametric, : Chernobyl! trL>n 6\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric =\nparametric, : Chernobyl! trL>n 6\n\n\nWarning in sqrt(sum.squares/one.delta): NaNs produced\n\n\nWarning in stats::qt(level/2 + 0.5, pred$df): NaNs produced\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric =\nparametric, : Chernobyl! trL>n 6\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric =\nparametric, : Chernobyl! trL>n 6\n\n\nWarning in sqrt(sum.squares/one.delta): NaNs produced\n\n\nWarning in stats::qt(level/2 + 0.5, pred$df): NaNs produced\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric =\nparametric, : Chernobyl! trL>n 6\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric =\nparametric, : Chernobyl! trL>n 6\n\n\nWarning in sqrt(sum.squares/one.delta): NaNs produced\n\n\nWarning in stats::qt(level/2 + 0.5, pred$df): NaNs produced\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric =\nparametric, : Chernobyl! trL>n 6\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric =\nparametric, : Chernobyl! trL>n 6\n\n\nWarning in sqrt(sum.squares/one.delta): NaNs produced\n\n\nWarning in stats::qt(level/2 + 0.5, pred$df): NaNs produced\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric =\nparametric, : Chernobyl! trL>n 6\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric =\nparametric, : Chernobyl! trL>n 6\n\n\nWarning in sqrt(sum.squares/one.delta): NaNs produced\n\n\nWarning in stats::qt(level/2 + 0.5, pred$df): NaNs produced\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric =\nparametric, : Chernobyl! trL>n 6\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric =\nparametric, : Chernobyl! trL>n 6\n\n\nWarning in sqrt(sum.squares/one.delta): NaNs produced\n\n\nWarning in stats::qt(level/2 + 0.5, pred$df): NaNs produced\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric =\nparametric, : Chernobyl! trL>n 6\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric =\nparametric, : Chernobyl! trL>n 6\n\n\nWarning in sqrt(sum.squares/one.delta): NaNs produced\n\n\nWarning in stats::qt(level/2 + 0.5, pred$df): NaNs produced\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric =\nparametric, : Chernobyl! trL>n 6\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric =\nparametric, : Chernobyl! trL>n 6\n\n\nWarning in sqrt(sum.squares/one.delta): NaNs produced\n\n\nWarning in stats::qt(level/2 + 0.5, pred$df): NaNs produced\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric =\nparametric, : Chernobyl! trL>n 6\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric =\nparametric, : Chernobyl! trL>n 6\n\n\nWarning in sqrt(sum.squares/one.delta): NaNs produced\n\n\nWarning in stats::qt(level/2 + 0.5, pred$df): NaNs produced\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric =\nparametric, : Chernobyl! trL>n 6\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric =\nparametric, : Chernobyl! trL>n 6\n\n\nWarning in sqrt(sum.squares/one.delta): NaNs produced\n\n\nWarning in stats::qt(level/2 + 0.5, pred$df): NaNs produced\n\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\nWarning in max(ids, na.rm = TRUE): no non-missing arguments to max; returning\n-Inf\n\n\n\n\n\nAs you can see, 4 rooms and 5 room types of flats have similar trends, from 2017, it was on the downtrend up til 2019 before started picking up and increased until current year 2023.\nThe difference are, for 4 room and 5 rooms units, there are some months where there are big outliers, and the standard deviation away from the trend-line are much bigger compared to 3-Room type of flats. This means for 4 rooms and 5 room types of flats, there are certain transactions that are priced at much different prices compared to the group’s trend line"
  }
]